# Spelled out NN and Backprop

Micrograd is an autograd engine it allows you to do gradient really quickly which is important for learning. Backprop uses a lot of gradients.
- It recursively applies the calculus chain rule.
- NN is just mathematical expressions.
- Take input data, weights and do predictions + loss function.

Most of the work in these models is about efficiency. It's less about core algorithms.
